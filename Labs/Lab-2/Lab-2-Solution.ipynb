{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2- Numpy\n",
    "\n",
    "Read through the following notebook to get an introduction to numpy: [Numpy Intro](https://github.com/jrjohansson/scientific-python-lectures/blob/master/Lecture-2-Numpy.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1\n",
    "\n",
    "Let start with some basic reshape manipulations. Consider a classification task. We can imagine the training data X consisting of N examples each with M inputs, so the shape of X is (M,N). We usually express the output of the Neural Network, which for the training sample encodes the true class of each of the M examples in X, in a \"one-hot\" matrix of shape (N,C), where C is the number of classes and each row corresponds to the true class for the corresponding example in X. So for a given row Y[i], all elements are 0 except for the column corresponding to the true class.\n",
    "\n",
    "For example consider a classification task of separating between 4 classes. We'll call them A, B, C, and D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y=np.array( [ [0, 1, 0, 0], # Class B\n",
    "              [1, 0, 0, 0], # Class A\n",
    "              [0, 0, 1, 0], # Class C\n",
    "              [0, 0, 0, 1]  # Class D\n",
    "            ])\n",
    "\n",
    "print \"Shape of Y:\", Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets imagine that we want to change to a 2 classes instead by combining classes A with B and C with D. Use np.reshape and np.sum to create a new vector Y1. Hint: change the shape of Y into (8,2), sum along the correct axes, and change shape to (4,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "Y1= Y.reshape(8,2)\n",
    "Y1 = Y1.sum(axis=1).reshape(4,2)\n",
    "print Y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2\n",
    "\n",
    "Oftentimes we find that neutral networks work best when their input is mostly between 0,1. Below, we create a random dataset that is normal distributed (mean of 4, sigma of 10). Shift the data so that the mean is 0.5 and 68% of the data lies between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.92468376851\n",
      "-23.6033997875\n",
      "32.947226614\n"
     ]
    }
   ],
   "source": [
    "X=np.random.normal(4,10,1000)\n",
    "print np.mean(X)\n",
    "print np.min(X)\n",
    "print np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original mean:  3.92468376851\n",
      "original std:  9.95592599526\n",
      "new mean: 0.5\n",
      "new std:  1.0\n"
     ]
    }
   ],
   "source": [
    "oldMean = np.mean(X)\n",
    "oldStd = np.std(X)\n",
    "print \"original mean: \", oldMean\n",
    "print \"original std: \", oldStd\n",
    "\n",
    "def squeeze(x,std,mean):\n",
    "    return (x+(std-1)*mean)/std\n",
    "\n",
    "def shift(x,oldMean,newMean):\n",
    "    return x-oldMean+newMean\n",
    "    \n",
    "X1 = squeeze(X,oldStd,oldMean)\n",
    "X1 = shift(X1,np.mean(X1),0.5)\n",
    "\n",
    "newStd = np.std(X1)\n",
    "newMean = np.mean(X1)\n",
    "print \"new mean:\", newMean\n",
    "print \"new std: \", newStd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3\n",
    "\n",
    "Using np.random.random and np.random.normal to generate two datasets. Then use np.where to repeat exercise 1.4 showing that one creates a flat distribution and the other does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements divided by length of set for flat distro:\n",
      "46\n",
      "49\n",
      "51\n",
      "elements divided by length of set for normal distro:\n",
      "6.43997777982\n",
      "-4.27072881446\n",
      "8.64936205561\n"
     ]
    }
   ],
   "source": [
    "flat = np.random.uniform(-10,10,1000)\n",
    "gaus = np.random.normal(0,20,1000)\n",
    "moose1 = np.where(flat > 9);\n",
    "moose2 = np.where(flat < -8);\n",
    "moose3 = np.where(flat > 0);\n",
    "camel1 = np.where(gaus > 9);\n",
    "camel2 = np.where(gaus < -8);\n",
    "camel3 = np.where(gaus > 0);\n",
    "\n",
    "\n",
    "print \"elements divided by length of set for flat distro:\"\n",
    "print len(moose1[0])\n",
    "print len(moose2[0])/2\n",
    "print len(moose3[0])/10\n",
    "print \"elements divided by length of set for normal distro:\"\n",
    "gausMax = max(gaus)\n",
    "gausMin = min(gaus)\n",
    "print len(camel1[0])/(gausMax-9)\n",
    "print len(camel2[0])/(gausMin-8)\n",
    "print len(camel3[0])/(gausMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.4\n",
    "\n",
    "Now lets play with some real data. We will load a file of example Neutrino interactions in LArTPC detector. There are 2 read out planes in the detector with 240 wires each, sampled 4096 times. Shift the images in the same way as exercise 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Eng', u'Track_length', u'enu_truth', u'features', u'lep_mom_truth', u'mode_truth', u'pdg']\n",
      "(2500, 2, 240, 4096)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f=h5py.File(\"/data/LArIAT/h5_files/nue_CC_3-1469384613.h5\",\"r\")\n",
    "print f.keys()\n",
    "images=f[\"features\"]\n",
    "print images.shape\n",
    "#number of particles, number of channels, number of wires, sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oldMean = np.mean(images)\n",
    "oldMin = np.min(images)\n",
    "oldMax = np.max(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1055\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "print oldMean\n",
    "print oldStd\n",
    "#print np.min(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
